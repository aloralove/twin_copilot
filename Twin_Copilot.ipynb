{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Twin Copoilt using Bayesian Network"
      ],
      "metadata": {
        "id": "c6HQn00LgsFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm8k7iBsjqCJ",
        "outputId": "9658ea2c-39d7-4789-9882-d86192ec7a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-0.1.24-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pgmpy) (2.1.0+cu118)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pgmpy) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pgmpy) (4.66.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pgmpy) (1.3.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from pgmpy) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pgmpy) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pgmpy) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pgmpy) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->pgmpy) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->pgmpy) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pgmpy) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pgmpy) (1.3.0)\n",
            "Installing collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poZvyyNxgaXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69269fc-437a-490b-95ce-214b7f360df0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User_ID Scene_Type Feature_Type Model_Feature\n",
            "0     3535        Map      GeoJSON       Measure\n",
            "1      723   Standard        Model       Measure\n",
            "2     2772   Standard         Text       Measure\n",
            "3     4922   Standard        Model       Measure\n",
            "4     2534   Standard        Model       Measure\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# Define possible scene types and the features available in each\n",
        "scene_types = ['Standard', 'Map', 'Virtual_Tour']\n",
        "features_by_scene = {\n",
        "    'Standard': ['Model', 'Text', 'Image'],\n",
        "    'Map': ['Model', 'Text', 'Image', 'GeoJSON'],\n",
        "    'Virtual_Tour': ['Model', 'Text', 'Image']\n",
        "}\n",
        "model_features = ['Translate', 'Measure', 'Rotate', 'Scale']\n",
        "\n",
        "# Function to generate a random timestamp\n",
        "def random_timestamp(start, end):\n",
        "    return start + timedelta(\n",
        "        seconds=random.randint(0, int((end - start).total_seconds())),\n",
        "    )\n",
        "\n",
        "# Function to generate fake data\n",
        "def generate_data(num_users, num_actions):\n",
        "    data = []\n",
        "    start_date = datetime(2023, 1, 1)\n",
        "    end_date = datetime(2023, 12, 31)\n",
        "\n",
        "    for _ in range(num_actions):\n",
        "        user_id = random.randint(1, num_users)\n",
        "        scene_type = 'Standard' if random.random() < 0.7 else random.choice(scene_types)\n",
        "\n",
        "        # Adjusting preferences for 'GeoJSON' and 'Model'\n",
        "        # When in Map choose GeoJSON 60% of the time.\n",
        "        if scene_type == 'Map':\n",
        "            feature_type = 'GeoJSON' if random.random() < 0.6 else random.choice(features_by_scene[scene_type])\n",
        "        elif scene_type == 'Standard':\n",
        "            feature_type = 'Model' if random.random() < 0.6 else random.choice(features_by_scene[scene_type])\n",
        "        elif scene_type == 'Virtual_Tour':\n",
        "            feature_type = 'Image' if random.random() < 0.9 else random.choice(features_by_scene[scene_type])\n",
        "        else:\n",
        "            feature_type = random.choice(features_by_scene[scene_type])\n",
        "\n",
        "        model_feature = 'Measure' if random.random() < 0.8 else random.choice(model_features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        timestamp = random_timestamp(start_date, end_date)\n",
        "\n",
        "        data.append([user_id, scene_type, feature_type, model_feature])\n",
        "\n",
        "    return pd.DataFrame(data, columns=['User_ID', 'Scene_Type', 'Feature_Type', 'Model_Feature'])\n",
        "\n",
        "# Generate the data\n",
        "fake_data = generate_data(10000, 1000000) #10000 Users 1,000,000 choices\n",
        "\n",
        "# Print the first few rows of the simulated data to verify it looks correct.\n",
        "print(fake_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Perpare data to fit into Bayesian Network\n",
        "\n",
        "# Step 1: One-hot encode 'Scene Type' and 'Feature Type'\n",
        "# This creates a new DataFrame with binary columns for each category\n",
        "scene_type_encoded = pd.get_dummies(fake_data['Scene_Type'], prefix='Scene')\n",
        "feature_type_encoded = pd.get_dummies(fake_data['Feature_Type'], prefix='Feature')\n",
        "model_feature_encoded = pd.get_dummies(fake_data['Model_Feature'], prefix='Model')\n",
        "\n",
        "# Step 2: Combine the one-hot encoded columns back into a single DataFrame\n",
        "simulated_data = pd.concat([scene_type_encoded, feature_type_encoded, model_feature_encoded], axis=1)\n",
        "\n",
        "# Step 3: Verify the structure\n",
        "print(simulated_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOJk12YvaXu1",
        "outputId": "8f978888-f252-496b-d9d0-ec8f5c4cfd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Scene_Map  Scene_Standard  Scene_Virtual_Tour  Feature_GeoJSON  \\\n",
            "0          1               0                   0                1   \n",
            "1          0               1                   0                0   \n",
            "2          0               1                   0                0   \n",
            "3          0               1                   0                0   \n",
            "4          0               1                   0                0   \n",
            "\n",
            "   Feature_Image  Feature_Model  Feature_Text  Model_Measure  Model_Rotate  \\\n",
            "0              0              0             0              1             0   \n",
            "1              0              1             0              1             0   \n",
            "2              0              0             1              1             0   \n",
            "3              0              1             0              1             0   \n",
            "4              0              1             0              1             0   \n",
            "\n",
            "   Model_Scale  Model_Translate  \n",
            "0            0                0  \n",
            "1            0                0  \n",
            "2            0                0  \n",
            "3            0                0  \n",
            "4            0                0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from pgmpy.sampling import BayesianModelInference, _return_samples\n",
        "from pgmpy.utils.mathext import sample_discrete, sample_discrete_maps\n",
        "import itertools\n",
        "from collections import defaultdict, namedtuple\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from pgmpy.factors import factor_product\n",
        "\n",
        "# Bayesian Network structure\n",
        "bayesNet = BayesianNetwork()\n",
        "\n",
        "bayesNet.add_node(\"Scene_Standard\")\n",
        "bayesNet.add_node(\"Scene_Map\")\n",
        "bayesNet.add_node(\"Scene_Virtual_Tour\")\n",
        "\n",
        "bayesNet.add_node(\"Feature_Model\")\n",
        "bayesNet.add_node(\"Feature_Text\")\n",
        "bayesNet.add_node(\"Feature_Image\")\n",
        "bayesNet.add_node(\"Feature_GeoJSON\")\n",
        "\n",
        "bayesNet.add_node(\"Model_Translate\")\n",
        "bayesNet.add_node(\"Model_Measure\")\n",
        "bayesNet.add_node(\"Model_Rotate\")\n",
        "bayesNet.add_node(\"Model_Scale\")\n",
        "\n",
        "bayesNet.add_edge(\"Scene_Standard\", \"Feature_Model\")\n",
        "bayesNet.add_edge(\"Scene_Map\", \"Feature_Model\")\n",
        "bayesNet.add_edge(\"Scene_Virtual_Tour\", \"Feature_Model\")\n",
        "\n",
        "bayesNet.add_edge(\"Scene_Standard\", \"Feature_Text\")\n",
        "bayesNet.add_edge(\"Scene_Map\", \"Feature_Text\")\n",
        "bayesNet.add_edge(\"Scene_Virtual_Tour\", \"Feature_Text\")\n",
        "\n",
        "bayesNet.add_edge(\"Scene_Standard\", \"Feature_Image\")\n",
        "bayesNet.add_edge(\"Scene_Map\", \"Feature_Image\")\n",
        "bayesNet.add_edge(\"Scene_Virtual_Tour\", \"Feature_Image\")\n",
        "\n",
        "bayesNet.add_edge(\"Scene_Map\", \"Feature_GeoJSON\")\n",
        "\n",
        "bayesNet.add_edge(\"Feature_Model\", \"Model_Translate\")\n",
        "bayesNet.add_edge(\"Feature_Model\", \"Model_Measure\")\n",
        "bayesNet.add_edge(\"Feature_Model\", \"Model_Rotate\")\n",
        "bayesNet.add_edge(\"Feature_Model\", \"Model_Scale\")\n",
        "\n",
        "# Split Data for Training and for Testing 80/20\n",
        "train_data, test_data = train_test_split(simulated_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the Bayesian Network with the new data (likelyhood of different states given parents)\n",
        "# learn the conditional probability distributions (CPDs) from your training data\n",
        "bayesNet.fit(train_data, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# # Print the learned CPDs\n",
        "for cpd in bayesNet.get_cpds():\n",
        "    print(f\"CPD of {cpd.variable}:\")\n",
        "    print(cpd)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkHyjgllg39k",
        "outputId": "4d12ae65-1d23-40bf-95e6-7a8ded7dc15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPD of Scene_Standard:\n",
            "+-------------------+----------+\n",
            "| Scene_Standard(0) | 0.200556 |\n",
            "+-------------------+----------+\n",
            "| Scene_Standard(1) | 0.799444 |\n",
            "+-------------------+----------+\n",
            "CPD of Scene_Map:\n",
            "+--------------+----------+\n",
            "| Scene_Map(0) | 0.899981 |\n",
            "+--------------+----------+\n",
            "| Scene_Map(1) | 0.100019 |\n",
            "+--------------+----------+\n",
            "CPD of Scene_Virtual_Tour:\n",
            "+-----------------------+----------+\n",
            "| Scene_Virtual_Tour(0) | 0.899463 |\n",
            "+-----------------------+----------+\n",
            "| Scene_Virtual_Tour(1) | 0.100538 |\n",
            "+-----------------------+----------+\n",
            "CPD of Feature_Model:\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Map          | Scene_Map(0)          | ... | Scene_Map(1)          |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Standard     | Scene_Standard(0)     | ... | Scene_Standard(1)     |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Virtual_Tour | Scene_Virtual_Tour(0) | ... | Scene_Virtual_Tour(1) |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Model(0)   | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Model(1)   | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "CPD of Feature_Text:\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Map          | Scene_Map(0)          | ... | Scene_Map(1)          |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Standard     | Scene_Standard(0)     | ... | Scene_Standard(1)     |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Virtual_Tour | Scene_Virtual_Tour(0) | ... | Scene_Virtual_Tour(1) |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Text(0)    | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Text(1)    | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "CPD of Feature_Image:\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Map          | Scene_Map(0)          | ... | Scene_Map(1)          |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Standard     | Scene_Standard(0)     | ... | Scene_Standard(1)     |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Scene_Virtual_Tour | Scene_Virtual_Tour(0) | ... | Scene_Virtual_Tour(1) |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Image(0)   | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "| Feature_Image(1)   | 0.5                   | ... | 0.5                   |\n",
            "+--------------------+-----------------------+-----+-----------------------+\n",
            "CPD of Feature_GeoJSON:\n",
            "+--------------------+--------------+--------------------+\n",
            "| Scene_Map          | Scene_Map(0) | Scene_Map(1)       |\n",
            "+--------------------+--------------+--------------------+\n",
            "| Feature_GeoJSON(0) | 1.0          | 0.3002936949322002 |\n",
            "+--------------------+--------------+--------------------+\n",
            "| Feature_GeoJSON(1) | 0.0          | 0.6997063050677997 |\n",
            "+--------------------+--------------+--------------------+\n",
            "CPD of Model_Translate:\n",
            "+--------------------+---------------------+--------------------+\n",
            "| Feature_Model      | Feature_Model(0)    | Feature_Model(1)   |\n",
            "+--------------------+---------------------+--------------------+\n",
            "| Model_Translate(0) | 0.9505264995417677  | 0.9498311776662034 |\n",
            "+--------------------+---------------------+--------------------+\n",
            "| Model_Translate(1) | 0.04947350045823228 | 0.0501688223337966 |\n",
            "+--------------------+---------------------+--------------------+\n",
            "CPD of Model_Measure:\n",
            "+------------------+---------------------+--------------------+\n",
            "| Feature_Model    | Feature_Model(0)    | Feature_Model(1)   |\n",
            "+------------------+---------------------+--------------------+\n",
            "| Model_Measure(0) | 0.14949282726201535 | 0.1502643978948335 |\n",
            "+------------------+---------------------+--------------------+\n",
            "| Model_Measure(1) | 0.8505071727379846  | 0.8497356021051665 |\n",
            "+------------------+---------------------+--------------------+\n",
            "CPD of Model_Rotate:\n",
            "+-----------------+----------------------+---------------------+\n",
            "| Feature_Model   | Feature_Model(0)     | Feature_Model(1)    |\n",
            "+-----------------+----------------------+---------------------+\n",
            "| Model_Rotate(0) | 0.9499124059376929   | 0.9499647330353379  |\n",
            "+-----------------+----------------------+---------------------+\n",
            "| Model_Rotate(1) | 0.050087594062307124 | 0.05003526696466208 |\n",
            "+-----------------+----------------------+---------------------+\n",
            "CPD of Model_Scale:\n",
            "+----------------+---------------------+---------------------+\n",
            "| Feature_Model  | Feature_Model(0)    | Feature_Model(1)    |\n",
            "+----------------+---------------------+---------------------+\n",
            "| Model_Scale(0) | 0.950068267258524   | 0.9499396914036252  |\n",
            "+----------------+---------------------+---------------------+\n",
            "| Model_Scale(1) | 0.04993173274147594 | 0.05006030859637481 |\n",
            "+----------------+---------------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bayesNet.check_model()\n",
        "print(\"Model is correct.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAL3SGplA_4A",
        "outputId": "c3d3f5a5-87eb-40c0-a74a-7aa74efa1567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver = VariableElimination(bayesNet)\n",
        "# also seen above\n",
        "feature_model_dist = solver.query(variables=['Feature_GeoJSON'], evidence={'Scene_Map': 1})\n",
        "print(\"Probability Distribution for GeoJSON given Map Scene=1:\")\n",
        "print(feature_model_dist)\n",
        "\n",
        "model_translate_dist = solver.query(variables=['Feature_Model'], evidence={'Scene_Standard': 1})\n",
        "print(\"Probability Distribution for Feature_Model given Scene_Standard=1:\")\n",
        "print(model_translate_dist)\n",
        "\n",
        "model_translate_dist = solver.query(variables=['Model_Measure'], evidence={'Feature_Model': 1})\n",
        "print(\"Probability Distribution for Model_Measure given Feature_Model=1:\")\n",
        "print(model_translate_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s67kTdYmP9Ys",
        "outputId": "acbb0edd-1c38-4648-fae5-ea2e17558cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability Distribution for GeoJSON given Map Scene=1:\n",
            "+--------------------+------------------------+\n",
            "| Feature_GeoJSON    |   phi(Feature_GeoJSON) |\n",
            "+====================+========================+\n",
            "| Feature_GeoJSON(0) |                 0.3003 |\n",
            "+--------------------+------------------------+\n",
            "| Feature_GeoJSON(1) |                 0.6997 |\n",
            "+--------------------+------------------------+\n",
            "Probability Distribution for Feature_Model given Scene_Standard=1:\n",
            "+------------------+----------------------+\n",
            "| Feature_Model    |   phi(Feature_Model) |\n",
            "+==================+======================+\n",
            "| Feature_Model(0) |               0.3119 |\n",
            "+------------------+----------------------+\n",
            "| Feature_Model(1) |               0.6881 |\n",
            "+------------------+----------------------+\n",
            "Probability Distribution for Model_Measure given Feature_Model=1:\n",
            "+------------------+----------------------+\n",
            "| Model_Measure    |   phi(Model_Measure) |\n",
            "+==================+======================+\n",
            "| Model_Measure(0) |               0.1503 |\n",
            "+------------------+----------------------+\n",
            "| Model_Measure(1) |               0.8497 |\n",
            "+------------------+----------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Independencies\n",
        "independencies = bayesNet.local_independencies(['Scene_Standard', 'Scene_Map', 'Scene_Virtual_Tour',\n",
        "                                                'Feature_Model', 'Feature_Text', 'Feature_Image',\n",
        "                                                'Feature_GeoJSON', 'Model_Translate', 'Model_Measure',\n",
        "                                                'Model_Rotate', 'Model_Scale'])\n",
        "print(independencies)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al4WYlLnO8NG",
        "outputId": "af9380be-9bfe-4cc5-d905-91d6841ddc00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Scene_Standard ⟂ Scene_Map, Scene_Virtual_Tour, Feature_GeoJSON)\n",
            "(Scene_Map ⟂ Scene_Virtual_Tour, Scene_Standard)\n",
            "(Scene_Virtual_Tour ⟂ Scene_Map, Scene_Standard, Feature_GeoJSON)\n",
            "(Feature_Model ⟂ Feature_Text, Feature_Image, Feature_GeoJSON | Scene_Map, Scene_Virtual_Tour, Scene_Standard)\n",
            "(Feature_Text ⟂ Feature_Model, Model_Scale, Model_Translate, Model_Rotate, Feature_Image, Model_Measure, Feature_GeoJSON | Scene_Map, Scene_Virtual_Tour, Scene_Standard)\n",
            "(Feature_Image ⟂ Feature_Model, Model_Scale, Model_Translate, Feature_Text, Model_Rotate, Model_Measure, Feature_GeoJSON | Scene_Map, Scene_Virtual_Tour, Scene_Standard)\n",
            "(Feature_GeoJSON ⟂ Model_Translate, Feature_Text, Feature_Image, Model_Measure, Feature_Model, Model_Scale, Scene_Virtual_Tour, Model_Rotate, Scene_Standard | Scene_Map)\n",
            "(Model_Translate ⟂ Scene_Map, Feature_Text, Feature_Image, Model_Measure, Model_Scale, Scene_Virtual_Tour, Model_Rotate, Scene_Standard, Feature_GeoJSON | Feature_Model)\n",
            "(Model_Measure ⟂ Scene_Map, Model_Translate, Feature_Text, Feature_Image, Model_Scale, Scene_Virtual_Tour, Model_Rotate, Scene_Standard, Feature_GeoJSON | Feature_Model)\n",
            "(Model_Rotate ⟂ Scene_Map, Model_Translate, Feature_Text, Feature_Image, Model_Measure, Model_Scale, Scene_Virtual_Tour, Scene_Standard, Feature_GeoJSON | Feature_Model)\n",
            "(Model_Scale ⟂ Scene_Map, Model_Translate, Feature_Text, Feature_Image, Model_Measure, Scene_Virtual_Tour, Model_Rotate, Scene_Standard, Feature_GeoJSON | Feature_Model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize the Variable Elimination solver\n",
        "inference = VariableElimination(bayesNet)\n",
        "\n",
        "# Evaluate test data vs perdictions\n",
        "# Prob GeoJSON given Map\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "for index, row in test_data.iterrows():\n",
        "    actual_value = row['Feature_GeoJSON']\n",
        "    actuals.append(actual_value)\n",
        "\n",
        "    # Extract the evidence for 'GeoJSON' from its parent node 'Scene_Map' (true or false)\n",
        "    evidence = {'Scene_Map': row['Scene_Map']}\n",
        "\n",
        "    # Query the Bayesian network to get the probability distribution for 'GeoJSON'\n",
        "    predicted_distribution = inference.query(variables=['Feature_GeoJSON'], evidence=evidence)\n",
        "\n",
        "    # Convert the predicted probability distribution to a single predicted state\n",
        "    predicted_state = np.argmax(predicted_distribution.values)\n",
        "    predictions.append(predicted_state)\n",
        "\n",
        "accuracy = accuracy_score(actuals, predictions)\n",
        "\n",
        "print(f\"Accuracy of the Bayesian network on the test set for P(GeoJSON given Map): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPhzOQ9Zzjw",
        "outputId": "fff34407-38d5-42a6-a46e-a8c44edb4c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Bayesian network on the test set for P(GeoJSON given Map): 0.96982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prob Measurement given Model\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "for index, row in test_data.iterrows():\n",
        "    actual_value = row['Model_Measure']\n",
        "    actuals.append(actual_value)\n",
        "\n",
        "    # Extract the evidence for 'GeoJSON' from its parent node 'Scene_Map' (true or false)\n",
        "    evidence = {'Feature_Model': row['Feature_Model']}\n",
        "\n",
        "    # Query the Bayesian network to get the probability distribution for 'GeoJSON'\n",
        "    predicted_distribution = inference.query(variables=['Model_Measure'], evidence=evidence)\n",
        "\n",
        "    # Convert the predicted probability distribution to a single predicted state\n",
        "    predicted_state = np.argmax(predicted_distribution.values)\n",
        "    predictions.append(predicted_state)\n",
        "\n",
        "accuracy = accuracy_score(actuals, predictions)\n",
        "\n",
        "print(f\"Accuracy of the Bayesian network on the test set for P(Measure given Model): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3vGKbgJd_IT",
        "outputId": "7726b55a-6d9f-4045-b5e7-3934a1059943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Bayesian network on the test set for P(Measure given Model): 0.851155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prob Model given Standard\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "for index, row in test_data.iterrows():\n",
        "    actual_value = row['Feature_Model']\n",
        "    actuals.append(actual_value)\n",
        "\n",
        "    # Extract the evidence for 'GeoJSON' from its parent node 'Scene_Map' (true or false)\n",
        "    evidence = {'Scene_Standard': row['Scene_Standard']}\n",
        "\n",
        "    # Query the Bayesian network to get the probability distribution for 'GeoJSON'\n",
        "    predicted_distribution = inference.query(variables=['Feature_Model'], evidence=evidence)\n",
        "\n",
        "    # Convert the predicted probability distribution to a single predicted state\n",
        "    predicted_state = np.argmax(predicted_distribution.values)\n",
        "    predictions.append(predicted_state)\n",
        "\n",
        "accuracy = accuracy_score(actuals, predictions)\n",
        "\n",
        "print(f\"Accuracy of the Bayesian network on the test set for P(Model given Standard): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jak355KBf192",
        "outputId": "e390a1e6-5e42-442c-b15c-8845a2a9b97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Bayesian network on the test set for P(Model given Standard): 0.77511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prob Measure given Standard\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "for index, row in test_data.iterrows():\n",
        "    actual_value = row['Model_Measure']\n",
        "    actuals.append(actual_value)\n",
        "\n",
        "    # Extract the evidence for 'GeoJSON' from its parent node 'Scene_Map' (true or false)\n",
        "    evidence = {'Scene_Standard': row['Scene_Standard']}\n",
        "\n",
        "    # Query the Bayesian network to get the probability distribution for 'GeoJSON'\n",
        "    predicted_distribution = inference.query(variables=['Model_Measure'], evidence=evidence)\n",
        "\n",
        "    # Convert the predicted probability distribution to a single predicted state\n",
        "    predicted_state = np.argmax(predicted_distribution.values)\n",
        "    predictions.append(predicted_state)\n",
        "\n",
        "accuracy = accuracy_score(actuals, predictions)\n",
        "\n",
        "print(f\"Accuracy of the Bayesian network on the test set for P(Measure given Standard): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VitMPAtUMpv",
        "outputId": "ee1c2d4c-8036-4fd4-e6d6-cbb31de24b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Bayesian network on the test set for P(Measure given Standard): 0.849745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_VprGpRe0D6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}